{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DevOps \u00b6 For Full Documentation click here Documents","title":"Home"},{"location":"#devops","text":"For Full Documentation click here Documents","title":"DevOps"},{"location":"about/","text":"About \u00b6 This is Saiteja Irrinki Working as Build & Release as a DevOps Engineer in Visualpath IT Services from Nov-2020 to TillDate. Experience in Configuration Management covering Build Management, Version Control, CodeQuality, Environment Administration, Defect Tracking, Release Management, Merging Strategies, Continous Integration and Continous Delivery, Cloud Computing, Container Orchestration, Scripting for Automation, Static Web Development, Orchestration, Technologies and Operating Systems \u2013 Linux, Windows. +91-9493322788 saitejairrinki91@gmail.com","title":"About"},{"location":"about/#about","text":"This is Saiteja Irrinki Working as Build & Release as a DevOps Engineer in Visualpath IT Services from Nov-2020 to TillDate. Experience in Configuration Management covering Build Management, Version Control, CodeQuality, Environment Administration, Defect Tracking, Release Management, Merging Strategies, Continous Integration and Continous Delivery, Cloud Computing, Container Orchestration, Scripting for Automation, Static Web Development, Orchestration, Technologies and Operating Systems \u2013 Linux, Windows. +91-9493322788 saitejairrinki91@gmail.com","title":"About"},{"location":"ansible/","text":"Ansible \u00b6 Installing Ansible Ubuntu sudo apt update sudo apt install software-properties-common sudo add-apt-repository --yes --update ppa:ansible/ansible sudo apt install ansible ansible --version CentOS sudo yum install epel-release sudo yum install ansible ansible --version Sample Inventory File \u00b6 Inventory ##Host Level webserver01 ansible_host =< Private IP > webserver02 ansible_host =< Private IP > webserver03 ansible_host =< Private IP > dbserver01 ansible_host =< Private IP > dbserver02 ansible_host =< Private IP > ansible_user = ubuntu ##Group Level [ Group1 ] webserverserver01 webserverserver02 webserverserver03 [ Group2 ] dbserver01 dbserver02 ##Parent Level [ dc_mumbai : children ] webservergrp dbsrvgrp ##Variables [ dc_mumbai : vars ] ansible_user =< user > ansible_ssh_private_key_file =< key - path > Info Host level has the Highest priority , If you mention anything like username or Keyfile etc. It will take only which are mentioned in the host level. Ansible Commands \u00b6 To test the connection of particular Remote Machine ansible -i <Inventoryfile path> -m ping <hostname> To test the connection of particular Group of Remote Machines ansible -i <Inventoryfile path> -m ping <Groupname> To test the connection of All Remote Machine ansible -i <Inventoryfile path> -m ping all To see details about the machine ansible -i <Inventoryfile path> -m setup <hostname> Ad hoc Commands Some Example Commands \u00b6 Copy files to Remote machines name starts with web ansible -i <Inventoryfile path> -m copy -a \"src=index,html dest=/var/www/html/index.html\" 'web*' --become Installing httpd in centos Remote machine ansible -i <Inventoryfile path> -m yum -a \"name=httpd state=present\" websrvgrp --become Start & Enable httpd in centos Remote machine ansible -i <Inventoryfile path> -m service -a \"name=httpd state=started enabled=yes\" websrvgrp --become Ansible Configuration File \u00b6 vim ansible.cfg Ansible Configuration File [ defaults ] host_key_checking = False inventory = <Inventory File Path> timeout = 20 log_path = /var/log/ansible-hbadger.log forks = 5 remote_port = 22 remote_user = <username> [ privilege_escalation ] become = True become_method = sudo become_user = root become_ask_pass = False","title":"Ansible"},{"location":"ansible/#ansible","text":"Installing Ansible Ubuntu sudo apt update sudo apt install software-properties-common sudo add-apt-repository --yes --update ppa:ansible/ansible sudo apt install ansible ansible --version CentOS sudo yum install epel-release sudo yum install ansible ansible --version","title":"Ansible"},{"location":"ansible/#sample-inventory-file","text":"Inventory ##Host Level webserver01 ansible_host =< Private IP > webserver02 ansible_host =< Private IP > webserver03 ansible_host =< Private IP > dbserver01 ansible_host =< Private IP > dbserver02 ansible_host =< Private IP > ansible_user = ubuntu ##Group Level [ Group1 ] webserverserver01 webserverserver02 webserverserver03 [ Group2 ] dbserver01 dbserver02 ##Parent Level [ dc_mumbai : children ] webservergrp dbsrvgrp ##Variables [ dc_mumbai : vars ] ansible_user =< user > ansible_ssh_private_key_file =< key - path > Info Host level has the Highest priority , If you mention anything like username or Keyfile etc. It will take only which are mentioned in the host level.","title":"Sample Inventory File"},{"location":"ansible/#ansible-commands","text":"To test the connection of particular Remote Machine ansible -i <Inventoryfile path> -m ping <hostname> To test the connection of particular Group of Remote Machines ansible -i <Inventoryfile path> -m ping <Groupname> To test the connection of All Remote Machine ansible -i <Inventoryfile path> -m ping all To see details about the machine ansible -i <Inventoryfile path> -m setup <hostname> Ad hoc Commands","title":"Ansible Commands"},{"location":"ansible/#some-example-commands","text":"Copy files to Remote machines name starts with web ansible -i <Inventoryfile path> -m copy -a \"src=index,html dest=/var/www/html/index.html\" 'web*' --become Installing httpd in centos Remote machine ansible -i <Inventoryfile path> -m yum -a \"name=httpd state=present\" websrvgrp --become Start & Enable httpd in centos Remote machine ansible -i <Inventoryfile path> -m service -a \"name=httpd state=started enabled=yes\" websrvgrp --become","title":"Some Example Commands"},{"location":"ansible/#ansible-configuration-file","text":"vim ansible.cfg Ansible Configuration File [ defaults ] host_key_checking = False inventory = <Inventory File Path> timeout = 20 log_path = /var/log/ansible-hbadger.log forks = 5 remote_port = 22 remote_user = <username> [ privilege_escalation ] become = True become_method = sudo become_user = root become_ask_pass = False","title":"Ansible Configuration File"},{"location":"aws-cli/","text":"AWS CLI (Command Line Interface) \u00b6 Setting up IAM user \u00b6 Creating User with Access-key \u00b6 Set permissions & Attaching Policies \u00b6 Installing AWS-CLI \u00b6 sudo -i sudo apt update apt install awscli -y Configure AWS CLI with IAM user Credentials with specific Region \u00b6 aws configure Once it is done try some aws cli commands like aws s3 ls If u have any buckets in your s3 it will list EC2 \u2013 Elastic Compute Cloud \u00b6 Create a key pair \u00b6 aws ec2 create-key-pair --key-name <keypair-Name> --query 'KeyMaterial' --output text > <keypair-Name.pem> Delete a key pair \u00b6 To delete a key pair, run the aws ec2 delete-key-pair command, substituting MyKeyPair with the name of the pair to delete. aws ec2 delete-key-pair --key-name <keypair-Name> Create a Security Group & Adding Inbound rules \u00b6 aws ec2 create-security-group --group-name <security grp Name> --description \"<Description>\" curl https://checkip.amazonaws.com aws ec2 authorize-security-group-ingress --group-id <security group Id> --protocol tcp --port <port Number> --cidr <ip address> aws ec2 authorize-security-group-ingress --group-id <security grp Id>--protocol tcp --port 22 -8000 --cidr 0 .0.0.0/0 To view the initial information for my-sg, run the aws ec2 describe-security-groups command. For an EC2-Classic security group, you can reference it by its name. aws ec2 describe-security-groups --group-names <security grp Name> Delete your security group \u00b6 The following command example deletes the EC2-Classic security group named. aws ec2 delete-security-group --group-name <security grp Name> Launch Instance \u00b6 You can use the following command to launch a t2.micro instance in EC2-Classic. Replace the italicized parameter values with your own. You can get the ami Id\u2019s from documentation or console for your required Instance. aws ec2 run-instances --image-id <ami-Id> --count 1 --instance-type <type> --key-name <keypair-Name> --security-groups <security grp Name> Add a tag to your Instance \u00b6 aws ec2 create-tags --resources <Instance-Id>--tags Key = Name,Value = <value> Terminate your Instance \u00b6 To delete an instance, you use the command aws ec2 terminate-instances to delete it. aws ec2 terminate-instances --instance-ids <Instance-Id> Create Launch Template \u00b6 aws ec2 create-launch-template --launch-template-name <Name> \":[{\" AssociatePublicIpAddress \":true,\" DeviceIndex \":0,\" Ipv6AddressCount \":1,\" SubnetId \":\" pe \":\" <Instance type \",\" TagSpecifications \":[{\" ResourceType \":\" instance \",\" Tags \":[{\" Key \":\" Name \",\" Value \":\" <value> \"}]}]}' Delete Launch Template \u00b6 aws ec2 delete-launch-template --launch-template-id < template id> --region <region> Creating Auto-Scaling group \u00b6 aws autoscaling create-auto-scaling-group --auto-scaling-group-name <Name> --launch-LaunchTemplateId = <template \u2013 id > --min-size 2 --max-size 5 --vpc-zone-identifier \"subnet1-id,subnet2-id,subnet3-id\" Delete your Auto-Scaling Group \u00b6 aws autoscaling delete-auto-scaling-group --auto-scaling-group-name < Auto -Scaling group Name > EBS \u2013 Elastic Block Storage \u00b6 Create EBS Volume \u00b6 To create an empty General Purpose SSD (gp2) volume aws ec2 create-volume --volume-type <volume type> --size <size in number> --availability-zone <zone> To create an encrypted volume \u00b6 aws ec2 create-volume --volume-type <volume type> --size <size in number> --encrypted --availability-zone <zone> To create a volume with tags \u00b6 aws ec2 create-tags --resources <volume-id> --tags Key = Name,Value = <value> To Delete a Volume \u00b6 aws ec2 delete-volume --volume-id <volume Id> Output Output: None To create a snapshot \u00b6 This example command creates a snapshot of the volume with a volume ID of and a short description to identify the snapshot. aws ec2 create-snapshot --volume-id <volume Id> --description \"<Description>\" To create a snapshot with tags \u00b6 aws ec2 create-snapshot --volume-id <volume Id> --description 'Prod backup' --tag-specifications 'ResourceType=snapshot,Tags=[{Key=Name,Value=<value>},{Key=Database,Value=Mysql}]' To allocate an Elastic IP address for EC2-Classic \u00b6 The following allocate-address example allocates an Elastic IP address to use with an instance in EC2-Classic. aws ec2 allocate-address ELB \u2013 Elastic Load Balancer \u00b6 Create-load-balancer \u00b6 To create an Application load balancer \u00b6 The below commands to find subnet id & Instance Id aws ec2 describe-subnets aws ec2 describe-instances aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id> <subnet-Id> To create an Network load balancer \u00b6 aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id> To register instances with a load balancer \u00b6 aws elb register-instances-with-load-balancer --load-balancer-name <Load balancer Name> --instances <Instance-Id> To Delete a Specific Load balancer \u00b6 aws elbv2 delete-load-balancer --load-balancer-arn <arn end point> RDS - Relational Database Service \u00b6 Create-db-Instance \u00b6 aws rds create-db-instance --db-instance-identifier <db - Name> --db-instance-class <db.type> --engine <Database Engine> --master-username <username> --master-user-password <password> --allocated-storage <storage in numbers> To delete your db-Instance \u00b6 aws rds delete-db-instance --db-instance-identifier <db - Name> --final-db-snapshot-identifier <db - Name>-final-snap S3 \u2013 Simple Storage Service \u00b6 List Buckets & Objects \u00b6 To list your buckets, folders, or objects, use the s3 ls command. Using the command without a target or options lists all buckets. aws s3 ls aws s3 ls s3://<bucket name> Create a bucket \u00b6 Use the s3 mb command to make a bucket. Bucket names must be globally unique (unique across all of Amazon S3) and should be DNS compliant. aws s3 mb s3:// <bucket name> Copy objects \u00b6 Use the s3 cp command to copy objects from a bucket or a local directory aws s3 cp <file> s3:// <bucket name> aws s3 cp s3://< source bucket/file> s3://<destination-bucket> Move objects \u00b6 Use the s3 mv command to move objects from a bucket or a local directory. aws s3 mv < local file> s3:// <bucket name> aws s3 mv s3:// < source bucket/file> s3://<destination-bucket> Sync Objects \u00b6 aws s3 sync . s3://<bucket name> Delete Objects \u00b6 aws s3 rm s3://<bucket name/file> --recursive Empty Bucket \u00b6 aws s3 rm s3://<bucket name> --recursive Delete Bucket \u00b6 aws s3 rb s3://<bucket name> VPC \u2013 Virtual Private Cloud \u00b6 To create a VPC and subnets using the AWS CLI \u00b6 Create a VPC with a 10.0.0.0/16 CIDR block using the following create-vpc command. \u00b6 aws ec2 create-vpc --cidr-block <Ip address> --query Vpc.VpcId --output text Using the VPC ID from the previous step, create a subnet with a 10.0.1.0/24 CIDR block using the following create-subnet command. \u00b6 aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address> Create a second subnet in your VPC with a 10.0.2.0/24 CIDR block. \u00b6 aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address> Create an internet gateway using the following create-internet-gateway command. \u00b6 aws ec2 create-internet-gateway --query InternetGateway.InternetGatewayId --output text Using the ID from the previous step, attach the internet gateway to your VPC using the following attach-internet-gateway command. \u00b6 aws ec2 attach-internet-gateway --vpc-id <vpc - Id>--internet-gateway-id <IGW - Id> Create a custom route table for your VPC using the following create-route-table command. \u00b6 aws ec2 create-route-table --vpc-id <vpc - Id>--query RouteTable.RouteTableId --output text Create a route in the route table that points all traffic (0.0.0.0/0) to the internet gateway using the following create-route command. \u00b6 aws ec2 create-route --route-table-id <route table - Id>--destination-cidr-block 0 .0.0.0/0 --gateway-id <Igw - Id> You can describe the route table using the following describe-route-tables command. \u00b6 aws ec2 describe-route-tables --route-table-id <route table - Id> The route table is currently not associated with any subnet. You need to associate it with a subnet in your VPC so that traffic from that subnet is routed to the internet gateway. \u00b6 aws ec2 describe-subnets --filters \"Name=vpc-id,Values=<vpc \u2013Id> --query \" Subnets [ * ] . { ID:SubnetId,CIDR:CidrBlock } \" You can choose which subnet to associate with the custom route table, for example, subnet-0c312202b3f26703a, and associate it using the associate-route-table command. This subnet is your public subnet. \u00b6 aws ec2 associate-route-table --subnet-id <subnet-Id> --route-table-id <route table - Id> CLEAN UP \u00b6 Delete your custom route table: \u00b6 aws ec2 delete-route-table --route-table-id <route table - Id> Delete your subnets: \u00b6 aws ec2 delete-subnet --subnet-id <subnet-Id> Detach your internet gateway from your VPC: \u00b6 aws ec2 detach-internet-gateway --internet-gateway-id <Igw -Id> --vpc-id <vpc- Id> Delete your internet gateway: \u00b6 aws ec2 delete-internet-gateway --internet-gateway-id <Igw - Id> Delete your VPC: \u00b6 aws ec2 delete-vpc --vpc-id <vpc- Id> Cloud Watch \u00b6 Creating Alarm \u00b6 aws cloudwatch put-metric-alarm --alarm-name <Alarm name> --alarm-description \"<Description>\" --metric-name <Metric> --namespace AWS/EC2 --statistic Average --period 300 --threshold < 70 > --comparison-operator <GreaterThanThreshold> --dimensions \"Name=InstanceId,Value=<Id>\" --evaluation-periods 2 --alarm-actions <SNS \u2013 arn > --unit Percent Delete Your Alarm \u00b6 aws cloudwatch delete-alarms --alarm-names <Alarm name> Disable your Alarm \u00b6 aws cloudwatch disable-alarm-actions --alarm-names <Alarm name> Enable your Alarm \u00b6 aws cloudwatch enable-alarm-actions --alarm-names <Alarm name>","title":"AWS"},{"location":"aws-cli/#aws-cli-command-line-interface","text":"","title":"AWS CLI (Command Line Interface)"},{"location":"aws-cli/#setting-up-iam-user","text":"","title":"Setting up IAM user"},{"location":"aws-cli/#creating-user-with-access-key","text":"","title":"Creating User with Access-key"},{"location":"aws-cli/#set-permissions-attaching-policies","text":"","title":"Set permissions &amp; Attaching Policies"},{"location":"aws-cli/#installing-aws-cli","text":"sudo -i sudo apt update apt install awscli -y","title":"Installing AWS-CLI"},{"location":"aws-cli/#configure-aws-cli-with-iam-user-credentials-with-specific-region","text":"aws configure Once it is done try some aws cli commands like aws s3 ls If u have any buckets in your s3 it will list","title":"Configure AWS CLI with IAM user Credentials with specific Region"},{"location":"aws-cli/#ec2-elastic-compute-cloud","text":"","title":"EC2 \u2013 Elastic Compute Cloud"},{"location":"aws-cli/#create-a-key-pair","text":"aws ec2 create-key-pair --key-name <keypair-Name> --query 'KeyMaterial' --output text > <keypair-Name.pem>","title":"Create a key pair"},{"location":"aws-cli/#delete-a-key-pair","text":"To delete a key pair, run the aws ec2 delete-key-pair command, substituting MyKeyPair with the name of the pair to delete. aws ec2 delete-key-pair --key-name <keypair-Name>","title":"Delete a key pair"},{"location":"aws-cli/#create-a-security-group-adding-inbound-rules","text":"aws ec2 create-security-group --group-name <security grp Name> --description \"<Description>\" curl https://checkip.amazonaws.com aws ec2 authorize-security-group-ingress --group-id <security group Id> --protocol tcp --port <port Number> --cidr <ip address> aws ec2 authorize-security-group-ingress --group-id <security grp Id>--protocol tcp --port 22 -8000 --cidr 0 .0.0.0/0 To view the initial information for my-sg, run the aws ec2 describe-security-groups command. For an EC2-Classic security group, you can reference it by its name. aws ec2 describe-security-groups --group-names <security grp Name>","title":"Create a Security Group &amp; Adding Inbound rules"},{"location":"aws-cli/#delete-your-security-group","text":"The following command example deletes the EC2-Classic security group named. aws ec2 delete-security-group --group-name <security grp Name>","title":"Delete your security group"},{"location":"aws-cli/#launch-instance","text":"You can use the following command to launch a t2.micro instance in EC2-Classic. Replace the italicized parameter values with your own. You can get the ami Id\u2019s from documentation or console for your required Instance. aws ec2 run-instances --image-id <ami-Id> --count 1 --instance-type <type> --key-name <keypair-Name> --security-groups <security grp Name>","title":"Launch Instance"},{"location":"aws-cli/#add-a-tag-to-your-instance","text":"aws ec2 create-tags --resources <Instance-Id>--tags Key = Name,Value = <value>","title":"Add a tag to your Instance"},{"location":"aws-cli/#terminate-your-instance","text":"To delete an instance, you use the command aws ec2 terminate-instances to delete it. aws ec2 terminate-instances --instance-ids <Instance-Id>","title":"Terminate your Instance"},{"location":"aws-cli/#create-launch-template","text":"aws ec2 create-launch-template --launch-template-name <Name> \":[{\" AssociatePublicIpAddress \":true,\" DeviceIndex \":0,\" Ipv6AddressCount \":1,\" SubnetId \":\" pe \":\" <Instance type \",\" TagSpecifications \":[{\" ResourceType \":\" instance \",\" Tags \":[{\" Key \":\" Name \",\" Value \":\" <value> \"}]}]}'","title":"Create Launch Template"},{"location":"aws-cli/#delete-launch-template","text":"aws ec2 delete-launch-template --launch-template-id < template id> --region <region>","title":"Delete Launch Template"},{"location":"aws-cli/#creating-auto-scaling-group","text":"aws autoscaling create-auto-scaling-group --auto-scaling-group-name <Name> --launch-LaunchTemplateId = <template \u2013 id > --min-size 2 --max-size 5 --vpc-zone-identifier \"subnet1-id,subnet2-id,subnet3-id\"","title":"Creating Auto-Scaling group"},{"location":"aws-cli/#delete-your-auto-scaling-group","text":"aws autoscaling delete-auto-scaling-group --auto-scaling-group-name < Auto -Scaling group Name >","title":"Delete your Auto-Scaling Group"},{"location":"aws-cli/#ebs-elastic-block-storage","text":"","title":"EBS \u2013 Elastic Block Storage"},{"location":"aws-cli/#create-ebs-volume","text":"To create an empty General Purpose SSD (gp2) volume aws ec2 create-volume --volume-type <volume type> --size <size in number> --availability-zone <zone>","title":"Create EBS Volume"},{"location":"aws-cli/#to-create-an-encrypted-volume","text":"aws ec2 create-volume --volume-type <volume type> --size <size in number> --encrypted --availability-zone <zone>","title":"To create an encrypted volume"},{"location":"aws-cli/#to-create-a-volume-with-tags","text":"aws ec2 create-tags --resources <volume-id> --tags Key = Name,Value = <value>","title":"To create a volume with tags"},{"location":"aws-cli/#to-delete-a-volume","text":"aws ec2 delete-volume --volume-id <volume Id> Output Output: None","title":"To Delete a Volume"},{"location":"aws-cli/#to-create-a-snapshot","text":"This example command creates a snapshot of the volume with a volume ID of and a short description to identify the snapshot. aws ec2 create-snapshot --volume-id <volume Id> --description \"<Description>\"","title":"To create a snapshot"},{"location":"aws-cli/#to-create-a-snapshot-with-tags","text":"aws ec2 create-snapshot --volume-id <volume Id> --description 'Prod backup' --tag-specifications 'ResourceType=snapshot,Tags=[{Key=Name,Value=<value>},{Key=Database,Value=Mysql}]'","title":"To create a snapshot with tags"},{"location":"aws-cli/#to-allocate-an-elastic-ip-address-for-ec2-classic","text":"The following allocate-address example allocates an Elastic IP address to use with an instance in EC2-Classic. aws ec2 allocate-address","title":"To allocate an Elastic IP address for EC2-Classic"},{"location":"aws-cli/#elb-elastic-load-balancer","text":"","title":"ELB \u2013 Elastic Load Balancer"},{"location":"aws-cli/#create-load-balancer","text":"","title":"Create-load-balancer"},{"location":"aws-cli/#to-create-an-application-load-balancer","text":"The below commands to find subnet id & Instance Id aws ec2 describe-subnets aws ec2 describe-instances aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id> <subnet-Id>","title":"To create an Application load balancer"},{"location":"aws-cli/#to-create-an-network-load-balancer","text":"aws elbv2 create-load-balancer --name <Load balancer Name>--type <type> --subnets <subnet-Id>","title":"To create an Network load balancer"},{"location":"aws-cli/#to-register-instances-with-a-load-balancer","text":"aws elb register-instances-with-load-balancer --load-balancer-name <Load balancer Name> --instances <Instance-Id>","title":"To register instances with a load balancer"},{"location":"aws-cli/#to-delete-a-specific-load-balancer","text":"aws elbv2 delete-load-balancer --load-balancer-arn <arn end point>","title":"To Delete a Specific Load balancer"},{"location":"aws-cli/#rds-relational-database-service","text":"","title":"RDS - Relational Database Service"},{"location":"aws-cli/#create-db-instance","text":"aws rds create-db-instance --db-instance-identifier <db - Name> --db-instance-class <db.type> --engine <Database Engine> --master-username <username> --master-user-password <password> --allocated-storage <storage in numbers>","title":"Create-db-Instance"},{"location":"aws-cli/#to-delete-your-db-instance","text":"aws rds delete-db-instance --db-instance-identifier <db - Name> --final-db-snapshot-identifier <db - Name>-final-snap","title":"To delete your db-Instance"},{"location":"aws-cli/#s3-simple-storage-service","text":"","title":"S3 \u2013 Simple Storage Service"},{"location":"aws-cli/#list-buckets-objects","text":"To list your buckets, folders, or objects, use the s3 ls command. Using the command without a target or options lists all buckets. aws s3 ls aws s3 ls s3://<bucket name>","title":"List Buckets &amp; Objects"},{"location":"aws-cli/#create-a-bucket","text":"Use the s3 mb command to make a bucket. Bucket names must be globally unique (unique across all of Amazon S3) and should be DNS compliant. aws s3 mb s3:// <bucket name>","title":"Create a bucket"},{"location":"aws-cli/#copy-objects","text":"Use the s3 cp command to copy objects from a bucket or a local directory aws s3 cp <file> s3:// <bucket name> aws s3 cp s3://< source bucket/file> s3://<destination-bucket>","title":"Copy objects"},{"location":"aws-cli/#move-objects","text":"Use the s3 mv command to move objects from a bucket or a local directory. aws s3 mv < local file> s3:// <bucket name> aws s3 mv s3:// < source bucket/file> s3://<destination-bucket>","title":"Move objects"},{"location":"aws-cli/#sync-objects","text":"aws s3 sync . s3://<bucket name>","title":"Sync Objects"},{"location":"aws-cli/#delete-objects","text":"aws s3 rm s3://<bucket name/file> --recursive","title":"Delete Objects"},{"location":"aws-cli/#empty-bucket","text":"aws s3 rm s3://<bucket name> --recursive","title":"Empty Bucket"},{"location":"aws-cli/#delete-bucket","text":"aws s3 rb s3://<bucket name>","title":"Delete Bucket"},{"location":"aws-cli/#vpc-virtual-private-cloud","text":"","title":"VPC \u2013 Virtual Private Cloud"},{"location":"aws-cli/#to-create-a-vpc-and-subnets-using-the-aws-cli","text":"","title":"To create a VPC and subnets using the AWS CLI"},{"location":"aws-cli/#create-a-vpc-with-a-1000016-cidr-block-using-the-following-create-vpc-command","text":"aws ec2 create-vpc --cidr-block <Ip address> --query Vpc.VpcId --output text","title":"Create a VPC with a 10.0.0.0/16 CIDR block using the following create-vpc command."},{"location":"aws-cli/#using-the-vpc-id-from-the-previous-step-create-a-subnet-with-a-1001024-cidr-block-using-the-following-create-subnet-command","text":"aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address>","title":"Using the VPC ID from the previous step, create a subnet with a 10.0.1.0/24 CIDR block using the following create-subnet command."},{"location":"aws-cli/#create-a-second-subnet-in-your-vpc-with-a-1002024-cidr-block","text":"aws ec2 create-subnet --vpc-id <vpc - Id>--cidr-block <Ip address>","title":"Create a second subnet in your VPC with a 10.0.2.0/24 CIDR block."},{"location":"aws-cli/#create-an-internet-gateway-using-the-following-create-internet-gateway-command","text":"aws ec2 create-internet-gateway --query InternetGateway.InternetGatewayId --output text","title":"Create an internet gateway using the following create-internet-gateway command."},{"location":"aws-cli/#using-the-id-from-the-previous-step-attach-the-internet-gateway-to-your-vpc-using-the-following-attach-internet-gateway-command","text":"aws ec2 attach-internet-gateway --vpc-id <vpc - Id>--internet-gateway-id <IGW - Id>","title":"Using the ID from the previous step, attach the internet gateway to your VPC using the following attach-internet-gateway command."},{"location":"aws-cli/#create-a-custom-route-table-for-your-vpc-using-the-following-create-route-table-command","text":"aws ec2 create-route-table --vpc-id <vpc - Id>--query RouteTable.RouteTableId --output text","title":"Create a custom route table for your VPC using the following create-route-table command."},{"location":"aws-cli/#create-a-route-in-the-route-table-that-points-all-traffic-00000-to-the-internet-gateway-using-the-following-create-route-command","text":"aws ec2 create-route --route-table-id <route table - Id>--destination-cidr-block 0 .0.0.0/0 --gateway-id <Igw - Id>","title":"Create a route in the route table that points all traffic (0.0.0.0/0) to the internet gateway using the following create-route command."},{"location":"aws-cli/#you-can-describe-the-route-table-using-the-following-describe-route-tables-command","text":"aws ec2 describe-route-tables --route-table-id <route table - Id>","title":"You can describe the route table using the following describe-route-tables command."},{"location":"aws-cli/#the-route-table-is-currently-not-associated-with-any-subnet-you-need-to-associate-it-with-a-subnet-in-your-vpc-so-that-traffic-from-that-subnet-is-routed-to-the-internet-gateway","text":"aws ec2 describe-subnets --filters \"Name=vpc-id,Values=<vpc \u2013Id> --query \" Subnets [ * ] . { ID:SubnetId,CIDR:CidrBlock } \"","title":"The route table is currently not associated with any subnet. You need to associate it with a subnet in your VPC so that traffic from that subnet is routed to the internet gateway."},{"location":"aws-cli/#you-can-choose-which-subnet-to-associate-with-the-custom-route-table-for-example-subnet-0c312202b3f26703a-and-associate-it-using-the-associate-route-table-command-this-subnet-is-your-public-subnet","text":"aws ec2 associate-route-table --subnet-id <subnet-Id> --route-table-id <route table - Id>","title":"You can choose which subnet to associate with the custom route table, for example, subnet-0c312202b3f26703a, and associate it using the associate-route-table command. This subnet is your public subnet."},{"location":"aws-cli/#clean-up","text":"","title":"CLEAN UP"},{"location":"aws-cli/#delete-your-custom-route-table","text":"aws ec2 delete-route-table --route-table-id <route table - Id>","title":"Delete your custom route table:"},{"location":"aws-cli/#delete-your-subnets","text":"aws ec2 delete-subnet --subnet-id <subnet-Id>","title":"Delete your subnets:"},{"location":"aws-cli/#detach-your-internet-gateway-from-your-vpc","text":"aws ec2 detach-internet-gateway --internet-gateway-id <Igw -Id> --vpc-id <vpc- Id>","title":"Detach your internet gateway from your VPC:"},{"location":"aws-cli/#delete-your-internet-gateway","text":"aws ec2 delete-internet-gateway --internet-gateway-id <Igw - Id>","title":"Delete your internet gateway:"},{"location":"aws-cli/#delete-your-vpc","text":"aws ec2 delete-vpc --vpc-id <vpc- Id>","title":"Delete your VPC:"},{"location":"aws-cli/#cloud-watch","text":"","title":"Cloud Watch"},{"location":"aws-cli/#creating-alarm","text":"aws cloudwatch put-metric-alarm --alarm-name <Alarm name> --alarm-description \"<Description>\" --metric-name <Metric> --namespace AWS/EC2 --statistic Average --period 300 --threshold < 70 > --comparison-operator <GreaterThanThreshold> --dimensions \"Name=InstanceId,Value=<Id>\" --evaluation-periods 2 --alarm-actions <SNS \u2013 arn > --unit Percent","title":"Creating Alarm"},{"location":"aws-cli/#delete-your-alarm","text":"aws cloudwatch delete-alarms --alarm-names <Alarm name>","title":"Delete Your Alarm"},{"location":"aws-cli/#disable-your-alarm","text":"aws cloudwatch disable-alarm-actions --alarm-names <Alarm name>","title":"Disable your Alarm"},{"location":"aws-cli/#enable-your-alarm","text":"aws cloudwatch enable-alarm-actions --alarm-names <Alarm name>","title":"Enable your Alarm"},{"location":"code/","text":"Code Example \u00b6 PHP \u00b6 class App { /** * @var string */ private $name; public __construct($name) { $this->name = $name; } } C \u00b6 public class App { private string Name { get ; set ;} public App ( string name ) { this . Name = name ; } } Json \u00b6 { \"result\" : \"success\" } Bash \u00b6 curl -H 'Content-type: application/json' http://localhost:8080/api/ vi /etc/resolvconf/resolv.conf.d/head C C++ #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Code Example"},{"location":"code/#code-example","text":"","title":"Code Example"},{"location":"code/#php","text":"class App { /** * @var string */ private $name; public __construct($name) { $this->name = $name; } }","title":"PHP"},{"location":"code/#c","text":"public class App { private string Name { get ; set ;} public App ( string name ) { this . Name = name ; } }","title":"C"},{"location":"code/#json","text":"{ \"result\" : \"success\" }","title":"Json"},{"location":"code/#bash","text":"curl -H 'Content-type: application/json' http://localhost:8080/api/ vi /etc/resolvconf/resolv.conf.d/head C C++ #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Bash"},{"location":"docker-setup/","text":"Install Docker Engine on Ubuntu & CentOS with Docker-Compose \u00b6 Docker Setup #!/bin/bash apt --help >>/dev/null if [ $? -eq 0 ] then echo \" INSTALLING DOCKER IN UBUNTU\" echo sudo apt update sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update sudo apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io -y sudo docker run hello-world else echo \" INSTALLING DOCKER IN CENTOS\" echo sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io -y sudo systemctl start docker sudo docker run hello-world fi echo \" Installing Docker Compose\" sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version","title":"Docker"},{"location":"docker-setup/#install-docker-engine-on-ubuntu-centos-with-docker-compose","text":"Docker Setup #!/bin/bash apt --help >>/dev/null if [ $? -eq 0 ] then echo \" INSTALLING DOCKER IN UBUNTU\" echo sudo apt update sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get update sudo apt-get -y install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg \\ lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io -y sudo docker run hello-world else echo \" INSTALLING DOCKER IN CENTOS\" echo sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine sudo yum install -y yum-utils sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io -y sudo systemctl start docker sudo docker run hello-world fi echo \" Installing Docker Compose\" sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose docker-compose --version","title":"Install Docker Engine on Ubuntu &amp; CentOS with Docker-Compose"},{"location":"git/","text":"Git Cheat Sheet \u00b6 GIT BASICS Command Usage git init <directory> Create empty Git repo in specified directory. Run with no arguments to initialize the current directory as a git repository. git clone <repo> Clone repo located at <repo> onto local machine. Original repo can be located on the local filesystem or on a remote machine via HTTP or SSH. git config user.name <name> Define author name to be used for all commits in current repo. Devs commonly use --global flag to set config options for current user. git add <directory> Stage all changes in <directory> for the next commit. Replace <directory> with a <file> to change a specific file.","title":"GIT"},{"location":"git/#git-cheat-sheet","text":"GIT BASICS Command Usage git init <directory> Create empty Git repo in specified directory. Run with no arguments to initialize the current directory as a git repository. git clone <repo> Clone repo located at <repo> onto local machine. Original repo can be located on the local filesystem or on a remote machine via HTTP or SSH. git config user.name <name> Define author name to be used for all commits in current repo. Devs commonly use --global flag to set config options for current user. git add <directory> Stage all changes in <directory> for the next commit. Replace <directory> with a <file> to change a specific file.","title":"Git Cheat Sheet"},{"location":"guide/","text":"Getting started \u00b6 Material for MkDocs is a theme for MkDocs , a static site generator geared towards (technical) project documentation. If you're familiar with Python, you can install Material for MkDocs with pip , the Python package manager. If not, we recommended using docker . Installation \u00b6 with pip recommended \u00b6 Material for MkDocs can be installed with pip : pip install mkdocs-material This will automatically install compatible versions of all dependencies: MkDocs , Markdown , Pygments and Python Markdown Extensions . Material for MkDocs always strives to support the latest versions, so there's no need to install those packages separately. Docker \u00b6 with docker \u00b6 The official Docker image is a great way to get up and running in a few minutes, as it comes with all dependencies pre-installed. Pull the image for the latest version with: docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entry point and serve is the default command. If you're not familiar with Docker don't worry, we have you covered in the following sections. The following plugins are bundled with the Docker image: mkdocs-minify-plugin mkdocs-redirects How to add plugins to the Docker image? Material for MkDocs bundles useful and common plugins while trying not to blow up the size of the official image. If the plugin you want to use is not included, create a new Dockerfile and extend the official Docker image with your custom installation routine: FROM squidfunk/mkdocs-material RUN pip install ... Next, you can build the image with the following command: docker build -t squidfunk/mkdocs-material . The new image can be used exactly like the official image. Apple Silicon (M1) and Raspberry Pi The official Docker image is only available for linux/amd64 . We recommend the third-party image by @afritzler if you want to run Material for MkDocs via Docker on arm64 or armv7 , as it is automatically built on every release: docker pull ghcr.io/afritzler/mkdocs-material GIT \u00b6 with git \u00b6 Material for MkDocs can be directly used from GitHub by cloning the repository into a subfolder of your project root which might be useful if you want to use the very latest version: git clone https://github.com/squidfunk/mkdocs-material.git The theme will reside in the folder mkdocs-material/material . When cloning from git , you must install all required dependencies yourself: pip install -e mkdocs-material","title":"Getting started"},{"location":"guide/#getting-started","text":"Material for MkDocs is a theme for MkDocs , a static site generator geared towards (technical) project documentation. If you're familiar with Python, you can install Material for MkDocs with pip , the Python package manager. If not, we recommended using docker .","title":"Getting started"},{"location":"guide/#installation","text":"","title":"Installation"},{"location":"guide/#with-pip","text":"Material for MkDocs can be installed with pip : pip install mkdocs-material This will automatically install compatible versions of all dependencies: MkDocs , Markdown , Pygments and Python Markdown Extensions . Material for MkDocs always strives to support the latest versions, so there's no need to install those packages separately.","title":"with pip"},{"location":"guide/#docker","text":"","title":"Docker"},{"location":"guide/#with-docker","text":"The official Docker image is a great way to get up and running in a few minutes, as it comes with all dependencies pre-installed. Pull the image for the latest version with: docker pull squidfunk/mkdocs-material The mkdocs executable is provided as an entry point and serve is the default command. If you're not familiar with Docker don't worry, we have you covered in the following sections. The following plugins are bundled with the Docker image: mkdocs-minify-plugin mkdocs-redirects How to add plugins to the Docker image? Material for MkDocs bundles useful and common plugins while trying not to blow up the size of the official image. If the plugin you want to use is not included, create a new Dockerfile and extend the official Docker image with your custom installation routine: FROM squidfunk/mkdocs-material RUN pip install ... Next, you can build the image with the following command: docker build -t squidfunk/mkdocs-material . The new image can be used exactly like the official image. Apple Silicon (M1) and Raspberry Pi The official Docker image is only available for linux/amd64 . We recommend the third-party image by @afritzler if you want to run Material for MkDocs via Docker on arm64 or armv7 , as it is automatically built on every release: docker pull ghcr.io/afritzler/mkdocs-material","title":"with docker"},{"location":"guide/#git","text":"","title":"GIT"},{"location":"guide/#with-git","text":"Material for MkDocs can be directly used from GitHub by cloning the repository into a subfolder of your project root which might be useful if you want to use the very latest version: git clone https://github.com/squidfunk/mkdocs-material.git The theme will reside in the folder mkdocs-material/material . When cloning from git , you must install all required dependencies yourself: pip install -e mkdocs-material","title":"with git"},{"location":"job_roles/","text":"DevOps ENGINEER ROLES \u00b6 AWS Tasks: \u00b6 Managing Ec2 Instances, EIP, Network Interfaces, Security Groups & Key Pairs Managing EBS Volumes, AMI & Snapshots (Backup & Restore, Migration etc) Setup & Managing Elastic Load Balancers, ACM & Autoscaling Groups Setting & Managing Cloudwatch Alarms on metrics from Ec2, ELB & RDS Creating & Managing RDS Instances, RDS Snapshots, Updating Parameters Groups AWS CLI for any AWS Tasks Cloud Migration using Lift & Shift Strategy on AWS, Services using \u00b6 VPC, Ec2, S3, Application Load Balancer, Route53 & CloudFront CDN IAM to give secure access to AWS account using MFA Tightly controlled Security Group for firewall rules of EC2 EBS volume for storage on Ec2, Snapshot for Backups of EBS Autoscaling for Automatic scaling of Ec2 instance based on CPU usage Modernization on AWS Cloud, Services used Beanstalk for PAAS for Tomcat Web App RDS for MySQL Database, Object storage S3 to store and retrieve files Route53 for Private & Public Hosted zones/Records Amazon MQ for fully managed RabbitMQ, ElastiCache for in memory datastore in cloud, Monitoring with CloudWatch, Notification using SNS, CloudFront for Content Delivery network AWS Cloud Automation using \u00b6 Ansible CloudFormation (Stacks) AWS Securities \u00b6 Inspector & Best practices IAM management Continuous Delivery of Java Web Application \u00b6 CICD Pipeline using Jenkins, Git, Maven, Nexus ,S3 & SonarQube Deploying Artifact to Beanstalk from Jenkins Jenkins Pipeline As A Code for CICD Jenkins Master/Slave setup Continuous Delivery on AWS Cloud using \u00b6 AWS Code Commit, Code Build & Code pipeline Configuration Management using Ansible \u00b6 Ansible AdHoc commands to execute remote tasks Ansible playbook for Service/Server Deployments Ansible playbook to setup VPC & Bastion Host on AWS Writing our own configuration file (ansible.cfg) Ansible Roles for modular & reusable automation framework Docker Containers \u00b6 Building customized docker images using Dockerfile Docker-compose to define & run MultiContainer Docker Application Kubernetes \u00b6 Creating Production grade K8s cluster using Kops Hosting Containerized Application on K8s cluster using Pod, Service, Replication Controller, Deployment, Secrets & ConfigMap MkDocs \u00b6 Designing and Building a Static Website using MkDocs","title":"Job roles"},{"location":"job_roles/#devops-engineer-roles","text":"","title":"DevOps ENGINEER ROLES"},{"location":"job_roles/#aws-tasks","text":"Managing Ec2 Instances, EIP, Network Interfaces, Security Groups & Key Pairs Managing EBS Volumes, AMI & Snapshots (Backup & Restore, Migration etc) Setup & Managing Elastic Load Balancers, ACM & Autoscaling Groups Setting & Managing Cloudwatch Alarms on metrics from Ec2, ELB & RDS Creating & Managing RDS Instances, RDS Snapshots, Updating Parameters Groups AWS CLI for any AWS Tasks","title":"AWS Tasks:"},{"location":"job_roles/#cloud-migration-using-lift-shift-strategy-on-aws-services-using","text":"VPC, Ec2, S3, Application Load Balancer, Route53 & CloudFront CDN IAM to give secure access to AWS account using MFA Tightly controlled Security Group for firewall rules of EC2 EBS volume for storage on Ec2, Snapshot for Backups of EBS Autoscaling for Automatic scaling of Ec2 instance based on CPU usage Modernization on AWS Cloud, Services used Beanstalk for PAAS for Tomcat Web App RDS for MySQL Database, Object storage S3 to store and retrieve files Route53 for Private & Public Hosted zones/Records Amazon MQ for fully managed RabbitMQ, ElastiCache for in memory datastore in cloud, Monitoring with CloudWatch, Notification using SNS, CloudFront for Content Delivery network","title":"Cloud Migration using Lift &amp; Shift Strategy on AWS, Services using"},{"location":"job_roles/#aws-cloud-automation-using","text":"Ansible CloudFormation (Stacks)","title":"AWS Cloud Automation using "},{"location":"job_roles/#aws-securities","text":"Inspector & Best practices IAM management","title":"AWS Securities"},{"location":"job_roles/#continuous-delivery-of-java-web-application","text":"CICD Pipeline using Jenkins, Git, Maven, Nexus ,S3 & SonarQube Deploying Artifact to Beanstalk from Jenkins Jenkins Pipeline As A Code for CICD Jenkins Master/Slave setup","title":"Continuous Delivery of Java Web Application  "},{"location":"job_roles/#continuous-delivery-on-aws-cloud-using","text":"AWS Code Commit, Code Build & Code pipeline","title":"Continuous Delivery on AWS Cloud using"},{"location":"job_roles/#configuration-management-using-ansible","text":"Ansible AdHoc commands to execute remote tasks Ansible playbook for Service/Server Deployments Ansible playbook to setup VPC & Bastion Host on AWS Writing our own configuration file (ansible.cfg) Ansible Roles for modular & reusable automation framework","title":"Configuration Management using Ansible "},{"location":"job_roles/#docker-containers","text":"Building customized docker images using Dockerfile Docker-compose to define & run MultiContainer Docker Application","title":"Docker Containers "},{"location":"job_roles/#kubernetes","text":"Creating Production grade K8s cluster using Kops Hosting Containerized Application on K8s cluster using Pod, Service, Replication Controller, Deployment, Secrets & ConfigMap","title":"Kubernetes "},{"location":"job_roles/#mkdocs","text":"Designing and Building a Static Website using MkDocs","title":"MkDocs"},{"location":"kops/","text":"Creating Kubernetes Cluster with KOPS \u00b6 Install AWS CLI apt update && apt install awscli -y Configure AWS CLI with IAM user Credentials with specific Region aws configure Note If you are using AWS Instance better to use IAM Role than Creating User with Access-key Check Whether AWS CLI Commands Working or not aws s3 ls Generate SSH Keys ssh-keygen Install kubectl binary with curl on Linux \u00b6 Download the latest release with the command: curl -LO \"https://dl.k8s.io/release/ $( curl -L -s https://dl.k8s.io/release/stable.txt ) /bin/linux/amd64/kubectl\" Install kubectl sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl kubectl version --client Installing Kubernetes with kops \u00b6 Download the latest release with the command: curl -LO https://github.com/kubernetes/kops/releases/download/ $( curl -s https://api.github.com/repos/kubernetes/kops/releases/lates | grep tag_name | cut -d '\"' -f 4 ) /kops-linux-amd64 Make the kops binary executable chmod +x kops-linux-amd64 Move the kops binary in to your PATH. sudo mv kops-linux-amd64 /usr/local/bin/kops kops Creating K8s Cluster with KOPS \u00b6 Kops commands to setup k8s cluster:- \u00b6 kops create cluster --name = saiteja.irrinki.xyz --state = s3://k8s-buckett --zone = eu-west-3a,eu-west-3b --node-count = 2 \u2013node-size = t2.micro --master- size = t2.micro --dns-zone = saiteja.irrinki.xyz --node-volume-size = 8 --master-volume-size = 8 It will create configuration of kops kops update cluster --name = saiteja.irrinki.xyz -- state = s3://k8s-bucket --yes --admin It will create kopsdata in S3 bucket. It start creating a cluster & it takes 10 mins kops validate cluster -- name = saiteja . irrinki . xyz -- state = s3 : //k8s-bucket It shows ur cluster is ready To Delete Cluster kops delete cluster -- name = saiteja . irrinki . xyz -- state = s3 : //k8s-bucket --yes","title":"Kubernetes"},{"location":"kops/#creating-kubernetes-cluster-with-kops","text":"Install AWS CLI apt update && apt install awscli -y Configure AWS CLI with IAM user Credentials with specific Region aws configure Note If you are using AWS Instance better to use IAM Role than Creating User with Access-key Check Whether AWS CLI Commands Working or not aws s3 ls Generate SSH Keys ssh-keygen","title":"Creating Kubernetes Cluster with KOPS"},{"location":"kops/#install-kubectl-binary-with-curl-on-linux","text":"Download the latest release with the command: curl -LO \"https://dl.k8s.io/release/ $( curl -L -s https://dl.k8s.io/release/stable.txt ) /bin/linux/amd64/kubectl\" Install kubectl sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl kubectl version --client","title":"Install kubectl binary with curl on Linux"},{"location":"kops/#installing-kubernetes-with-kops","text":"Download the latest release with the command: curl -LO https://github.com/kubernetes/kops/releases/download/ $( curl -s https://api.github.com/repos/kubernetes/kops/releases/lates | grep tag_name | cut -d '\"' -f 4 ) /kops-linux-amd64 Make the kops binary executable chmod +x kops-linux-amd64 Move the kops binary in to your PATH. sudo mv kops-linux-amd64 /usr/local/bin/kops kops","title":"Installing Kubernetes with kops"},{"location":"kops/#creating-k8s-cluster-with-kops","text":"","title":"Creating K8s Cluster with KOPS"},{"location":"kops/#kops-commands-to-setup-k8s-cluster-","text":"kops create cluster --name = saiteja.irrinki.xyz --state = s3://k8s-buckett --zone = eu-west-3a,eu-west-3b --node-count = 2 \u2013node-size = t2.micro --master- size = t2.micro --dns-zone = saiteja.irrinki.xyz --node-volume-size = 8 --master-volume-size = 8 It will create configuration of kops kops update cluster --name = saiteja.irrinki.xyz -- state = s3://k8s-bucket --yes --admin It will create kopsdata in S3 bucket. It start creating a cluster & it takes 10 mins kops validate cluster -- name = saiteja . irrinki . xyz -- state = s3 : //k8s-bucket It shows ur cluster is ready To Delete Cluster kops delete cluster -- name = saiteja . irrinki . xyz -- state = s3 : //k8s-bucket --yes","title":"Kops commands to setup k8s cluster:-"},{"location":"profile_summary/","text":"PROFILESUMMARY \u00b6 Around 1 year of experience in IT area comprising of configuration management, Deploy, CI/CD pipeline, AWS and DevOps methodologies. Expertise in troubleshooting the problems generated while building and deploying. Working Experience on Git, GitHub, Jenkins. Debugging issues if there is any failure in broken Jenkins build and maintaining Jenkins build pipeline. Expertise Knowledge in Source Code Management (version control system) tools using GIT. Experienced on Branching, Merging, and Tagging concepts in Version Control tool like GIT. Proficient in developing Continuous Integration / Continuous Delivery pipelines. Experience on containerization tools like Docker. Implemented Docker based Continues Integration and Deployment framework. Strong experience on build tools and packaging the source code using Maven. Scheduled builds overnight to support development needs using Jenkins, Git, and Maven. Experience in integrating Unit Tests and Code Quality Analysis Tools like SonarQube. Experience in using Nexus Repository Manager for Maven builds. Experience in orchestration tools like Kubernetes. Experience with services IAM, Compute Engine, Kubernetes Engine, Storage Buckets, VPC Network, and Pub Sub. Experience with Amazon Web services Creating, configuring and Managing EC2, Storage, IAM, S3, VPC, ELB, ECR, EKS, SNS, Route53 services in AWS. Experience in using Apache Tomcat & Red Hat Server application servers for deployments. Working experience on operating systems like Linux, Windows. Performed continuous Build and Deployments to multiple DEV, QA, PRE-Prod and PROD environments. Have knowledge in Shell Scripting, Google Cloud Platform. Ability to learn new skills quickly. ACADEMIC DETAILS \u00b6 B.Tech PROFESSIONAL \u00b6 Working as a DevOps Engineer at Visualpath IT Services Pvt Ltd from November 2020 to till now. STRENGTHS \u00b6 Flexibility and Adaptability to work in any environment Good Troubleshooting skills Willingness to accept any challenge irrespective of its complexity Good team player with positive attitude","title":"Profile summary"},{"location":"profile_summary/#profilesummary","text":"Around 1 year of experience in IT area comprising of configuration management, Deploy, CI/CD pipeline, AWS and DevOps methodologies. Expertise in troubleshooting the problems generated while building and deploying. Working Experience on Git, GitHub, Jenkins. Debugging issues if there is any failure in broken Jenkins build and maintaining Jenkins build pipeline. Expertise Knowledge in Source Code Management (version control system) tools using GIT. Experienced on Branching, Merging, and Tagging concepts in Version Control tool like GIT. Proficient in developing Continuous Integration / Continuous Delivery pipelines. Experience on containerization tools like Docker. Implemented Docker based Continues Integration and Deployment framework. Strong experience on build tools and packaging the source code using Maven. Scheduled builds overnight to support development needs using Jenkins, Git, and Maven. Experience in integrating Unit Tests and Code Quality Analysis Tools like SonarQube. Experience in using Nexus Repository Manager for Maven builds. Experience in orchestration tools like Kubernetes. Experience with services IAM, Compute Engine, Kubernetes Engine, Storage Buckets, VPC Network, and Pub Sub. Experience with Amazon Web services Creating, configuring and Managing EC2, Storage, IAM, S3, VPC, ELB, ECR, EKS, SNS, Route53 services in AWS. Experience in using Apache Tomcat & Red Hat Server application servers for deployments. Working experience on operating systems like Linux, Windows. Performed continuous Build and Deployments to multiple DEV, QA, PRE-Prod and PROD environments. Have knowledge in Shell Scripting, Google Cloud Platform. Ability to learn new skills quickly.","title":"PROFILESUMMARY"},{"location":"profile_summary/#academic-details","text":"B.Tech","title":"ACADEMIC DETAILS"},{"location":"profile_summary/#professional","text":"Working as a DevOps Engineer at Visualpath IT Services Pvt Ltd from November 2020 to till now.","title":"PROFESSIONAL"},{"location":"profile_summary/#strengths","text":"Flexibility and Adaptability to work in any environment Good Troubleshooting skills Willingness to accept any challenge irrespective of its complexity Good team player with positive attitude","title":"STRENGTHS"},{"location":"project/","text":"PROJECT 1 \u00b6 Name: Vprofile \u00b6 Duration: 2-Months \u00b6 Role: DevOps \u00b6 Environment : Git, GitHub, Maven, Apache Tomcat, Jenkins, Linux, SonarQube, Nexus, AWS, Ansible. \u00b6 Roles and Responsibilities : \u00b6 Configured Git with Jenkins and schedule jobs using POLL SCM option Installed and configured GIT and communicating with the repositories in GITHUB. Collaborate with different teams to deploy application code into Dev, QA, and Staging. Installing and updating the Jenkins plug-ins to achieve CI/CD. Responsible for installing Jenkins master and slave nodes. Created Jenkins CICD pipelines for continuous build & deployment and integrated Junit and SonarQube plugins in Jenkins for automated testing and for Code quality check. Integrated SonarQube with Jenkins for continuous inspection of code quality and analysis with SonarQube scanner for Maven. Managed Sonatype Nexus repositories to download the artifacts (jar, war & ear) during the build Wrote playbook manifests for deploying, configuring, and managing components. Managing the working environments through configuration management tools ansible. Working with developers and Testers to test the source code and applications through Jenkins plug-ins. Installation of apache, tomcat and troubleshooting web server issues. Proficient in deployment of WAR and EAR files in profiles and clustered environments. Administration and maintenance of servers using Red Hat Linux/Cento\u2019s 6 and 7. Installing and configuration of ansible server. * Implemented AWS solutions using EC2,S3,EBS,ELB, Route53, Auto scaling groups Built servers using AWS, importing volumes, launching EC2, creating Security groups, Auto- scaling, Load balancers (ELBs) using Cloud formation templates & AMI's using Infrastructure as a Service (IaaS). * Designed, built, and deployed a multitude application utilizing almost all the AWS stack (Including EC2, S3), focusing on high-availability, fault tolerance, and auto-scaling. * Configured ELB with different launch configurations using AMI and EC2 Autoscaling groups * Creating S3 buckets and S3 life cycle policies and bucket policies (Read/Write) * Creating EBS Volumes and snapshots and attaching to the EC2 instances PROJECT 2 \u00b6 Name: Emartin \u00b6 Duration : 3-Months \u00b6 Environment : Git, GitHub, Maven, Nexus, SonarQube, Jenkins, Docker, Kubernetes, AWS, Linux. \u00b6 Roles and Responsibilities : \u00b6 Involved in CI/CD process and integrated GIT, Nexus, SonarQube, Maven artifacts build with Jenkins and creating Docker image and using the Docker image to deploy over EKS (Kubernetes). Building and deploying various micro services in EKS. Creating and maintaining namespaces, configmaps, secrets, service, ingress, rbac in kubernetes. Implemented and maintained the Branching and build/ release strategies utilizing GIT. Experience with container-based deployments using Docker, working with Dockerimages, Docker Hub and Docker-registries and Kubernetes. Building/Maintaining Docker container clusters managed by Kubernetes Linux, Bash, GIT, Docker. Implemented docker-maven-plugin in maven pom to build docker images for all micro services and later used Docker file to build the docker images from the java jar files. Utilized Kubernetes for the runtime environment of the CI/CD system to build, test deploy. Experience in working on AWS and its services like AWS IAM, VPC, EC2, EKS, EBS, S3, ELB, Auto Scaling, Route 53, Cloud Front, Cloud Watch, Cloud Trail, and SNS. Experienced in Cloud automation using AWS Cloud Formation templates to create custom sized VPC, subnets, NAT, EC2 instances, ELB and Security groups. Experienced in creating complex IAM policies, Roles and user management for delegated access within AWS Identify, troubleshoot and resolve issues related to build and deploy process. Deploying Docker images in Kubernetes cluster using Yaml files and exposing the application to internet using service object.","title":"Project"},{"location":"project/#project-1","text":"","title":"PROJECT 1"},{"location":"project/#name-vprofile","text":"","title":"Name: Vprofile"},{"location":"project/#duration-2-months","text":"","title":"Duration: 2-Months"},{"location":"project/#role-devops","text":"","title":"Role: DevOps"},{"location":"project/#environment-git-github-maven-apache-tomcat-jenkins-linux-sonarqube-nexus-aws-ansible","text":"","title":"Environment : Git, GitHub, Maven, Apache Tomcat, Jenkins, Linux, SonarQube, Nexus, AWS, Ansible."},{"location":"project/#roles-and-responsibilities","text":"Configured Git with Jenkins and schedule jobs using POLL SCM option Installed and configured GIT and communicating with the repositories in GITHUB. Collaborate with different teams to deploy application code into Dev, QA, and Staging. Installing and updating the Jenkins plug-ins to achieve CI/CD. Responsible for installing Jenkins master and slave nodes. Created Jenkins CICD pipelines for continuous build & deployment and integrated Junit and SonarQube plugins in Jenkins for automated testing and for Code quality check. Integrated SonarQube with Jenkins for continuous inspection of code quality and analysis with SonarQube scanner for Maven. Managed Sonatype Nexus repositories to download the artifacts (jar, war & ear) during the build Wrote playbook manifests for deploying, configuring, and managing components. Managing the working environments through configuration management tools ansible. Working with developers and Testers to test the source code and applications through Jenkins plug-ins. Installation of apache, tomcat and troubleshooting web server issues. Proficient in deployment of WAR and EAR files in profiles and clustered environments. Administration and maintenance of servers using Red Hat Linux/Cento\u2019s 6 and 7. Installing and configuration of ansible server. * Implemented AWS solutions using EC2,S3,EBS,ELB, Route53, Auto scaling groups Built servers using AWS, importing volumes, launching EC2, creating Security groups, Auto- scaling, Load balancers (ELBs) using Cloud formation templates & AMI's using Infrastructure as a Service (IaaS). * Designed, built, and deployed a multitude application utilizing almost all the AWS stack (Including EC2, S3), focusing on high-availability, fault tolerance, and auto-scaling. * Configured ELB with different launch configurations using AMI and EC2 Autoscaling groups * Creating S3 buckets and S3 life cycle policies and bucket policies (Read/Write) * Creating EBS Volumes and snapshots and attaching to the EC2 instances","title":"Roles and Responsibilities :"},{"location":"project/#project-2","text":"","title":"PROJECT 2"},{"location":"project/#name-emartin","text":"","title":"Name: Emartin"},{"location":"project/#duration-3-months","text":"","title":"Duration : 3-Months"},{"location":"project/#environment-git-github-maven-nexus-sonarqube-jenkins-docker-kubernetes-aws-linux","text":"","title":"Environment : Git, GitHub, Maven, Nexus, SonarQube, Jenkins, Docker, Kubernetes, AWS, Linux."},{"location":"project/#roles-and-responsibilities_1","text":"Involved in CI/CD process and integrated GIT, Nexus, SonarQube, Maven artifacts build with Jenkins and creating Docker image and using the Docker image to deploy over EKS (Kubernetes). Building and deploying various micro services in EKS. Creating and maintaining namespaces, configmaps, secrets, service, ingress, rbac in kubernetes. Implemented and maintained the Branching and build/ release strategies utilizing GIT. Experience with container-based deployments using Docker, working with Dockerimages, Docker Hub and Docker-registries and Kubernetes. Building/Maintaining Docker container clusters managed by Kubernetes Linux, Bash, GIT, Docker. Implemented docker-maven-plugin in maven pom to build docker images for all micro services and later used Docker file to build the docker images from the java jar files. Utilized Kubernetes for the runtime environment of the CI/CD system to build, test deploy. Experience in working on AWS and its services like AWS IAM, VPC, EC2, EKS, EBS, S3, ELB, Auto Scaling, Route 53, Cloud Front, Cloud Watch, Cloud Trail, and SNS. Experienced in Cloud automation using AWS Cloud Formation templates to create custom sized VPC, subnets, NAT, EC2 instances, ELB and Security groups. Experienced in creating complex IAM policies, Roles and user management for delegated access within AWS Identify, troubleshoot and resolve issues related to build and deploy process. Deploying Docker images in Kubernetes cluster using Yaml files and exposing the application to internet using service object.","title":"Roles and Responsibilities :"},{"location":"resume/","text":"To view my Resume Click here Resume","title":"Resume"},{"location":"technical_skills/","text":"TECHNICAL SKILLS \u00b6 Category Tools Technologies & Softwares Operating Systems - Linux Windows Virtualization - Vagrant Scripting Languages - Shell Scripting, Python Containerization Tools - Docker Kubernetes Configuration Management Tool - Ansible Cloud Platform - Amazon Web Services Version Control Tool - GIT Build Software - Maven Continuous Integration Tool - Jenkins Web/App Server - Apache Tomcat Static Web Development - MkDocs Databases - RDS MySQL","title":"Technical skills"},{"location":"technical_skills/#technical-skills","text":"Category Tools Technologies & Softwares Operating Systems - Linux Windows Virtualization - Vagrant Scripting Languages - Shell Scripting, Python Containerization Tools - Docker Kubernetes Configuration Management Tool - Ansible Cloud Platform - Amazon Web Services Version Control Tool - GIT Build Software - Maven Continuous Integration Tool - Jenkins Web/App Server - Apache Tomcat Static Web Development - MkDocs Databases - RDS MySQL","title":"TECHNICAL SKILLS"},{"location":"test/","text":"Tables \u00b6 number name Role 00 saiteja DevOps Engineeer Number Notebook Data/Model Exercises & Extra-curriculum Slides 00 TensorFlow Fundamentals Go to exercises & extra-curriculum Go to slides 01 TensorFlow Regression Go to exercises & extra-curriculum Go to slides 02 TensorFlow Classification Go to exercises & extra-curriculum Go to slides Admonitions \u00b6 Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Method Description GET Fetch resource PUT Update resource DELETE Delete resource Buttons \u00b6 Send Subscribe to our newsletter Subscribe to our newsletter Formatting Text \u00b6 Text can be {--deleted--} and replacement text {++added++}. This can also be combined into { one~>a single } operation. { Highlighting } is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} This was marked This was inserted This was deleted H 2 0 A T A Ctrl + Alt + Del Icons & Emojis \u00b6 \u2013 material/account-circle.svg \u2013 fontawesome/regular/laugh-wink.svg \u2013 octicons/repo-push-16.svg \u2013 Medium \u2013 Twitter \u2013 Facebook :fontawesome-brands-note: :fontawesome-brands-cloud: :fontawesome-brands-laptop: List \u00b6 Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque Tags \u00b6 tags: - insiders - brand new ... Multiple-Code \u00b6 C C++ #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Test"},{"location":"test/#tables","text":"number name Role 00 saiteja DevOps Engineeer Number Notebook Data/Model Exercises & Extra-curriculum Slides 00 TensorFlow Fundamentals Go to exercises & extra-curriculum Go to slides 01 TensorFlow Regression Go to exercises & extra-curriculum Go to slides 02 TensorFlow Classification Go to exercises & extra-curriculum Go to slides","title":"Tables"},{"location":"test/#admonitions","text":"Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Method Description GET Fetch resource PUT Update resource DELETE Delete resource","title":"Admonitions"},{"location":"test/#buttons","text":"Send Subscribe to our newsletter Subscribe to our newsletter","title":"Buttons"},{"location":"test/#formatting-text","text":"Text can be {--deleted--} and replacement text {++added++}. This can also be combined into { one~>a single } operation. { Highlighting } is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} This was marked This was inserted This was deleted H 2 0 A T A Ctrl + Alt + Del","title":"Formatting Text"},{"location":"test/#icons-emojis","text":"\u2013 material/account-circle.svg \u2013 fontawesome/regular/laugh-wink.svg \u2013 octicons/repo-push-16.svg \u2013 Medium \u2013 Twitter \u2013 Facebook :fontawesome-brands-note: :fontawesome-brands-cloud: :fontawesome-brands-laptop:","title":"Icons &amp; Emojis"},{"location":"test/#list","text":"Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Lorem ipsum dolor sit amet Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Cras arcu libero Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Lorem ipsum dolor sit amet, consectetur adipiscing elit Vestibulum convallis sit amet nisi a tincidunt In hac habitasse platea dictumst In scelerisque nibh non dolor mollis congue sed et metus Praesent sed risus massa Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque","title":"List"},{"location":"test/#tags","text":"tags: - insiders - brand new ...","title":"Tags"},{"location":"test/#multiple-code","text":"C C++ #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } #include <iostream> int main ( void ) { std :: cout << \"Hello world!\" << std :: endl ; return 0 ; }","title":"Multiple-Code"}]}